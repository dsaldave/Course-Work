{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Why is it important to scale the inputs when using SVMs?\n",
    "( Use any data, e.g Iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines are typically applied to classification problems, where they use feature similarity to predict the class of a target variable. To explain how this works, the concept of a phase space is useful. Within a phase space, features are represented as having a spatial relationship to one another. The distance between features is used to make inferences about similarity (and implicitly about the structure of the data). Without scaling, these distances may have more to do with the magnitude, units, or range of each feature than the underlying relationship. For example, a persons weight expressed in grams would influence an algorithm that classifies a person as healthy or unhealthy more than the same weight expressed in pounds. So essentially, scaling makes it possible for a machine to discern the salient relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import seaborn as sb\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelBinarizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "from scipy import sparse\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data and divide it into features and target\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"]\n",
    "y = iris[\"target\"]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_transformed = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The average accuracy for unscaled data is 0.9466666666666667'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(loss = 'hinge')\n",
    "cv_results = model_selection.cross_val_score(model, X, y, cv =10, scoring = 'accuracy')\n",
    "results = cv_results.mean()\n",
    "# Accuracy = number of correct predictions / total number or predictions\n",
    "# A good metric for demonstrating the importance of feature scaling\n",
    "f'The average accuracy for unscaled data is {results}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The average accuracy for scaled data is 0.9133333333333333'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = model_selection.cross_val_score(model, X_transformed, y, cv = 10, scoring = 'accuracy')\n",
    "scaled_results = cv_results.mean()\n",
    "    \n",
    "f'The average accuracy for scaled data is {scaled_results}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is unexpected. A possible explanation is that some of the features are near constant, except for noise. If this is the case, standardization will amplify the noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon second thought, this result makes sense. The columns represent ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']. The scale is significant in this case, and by stripping the magnitudes we are losing information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. How can an SVM classifier output a confidence score when it classifies an instance? demonstrate with a block of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To return a confidence score, we have to use the SVC class rather than LinearSVC. The latter is implemented in the liblinear library rather than libsvm, which makes it well suited to classification with a linear kernel, but unfit for other tasks. The SVC class has a property 'probability' which can be set to true. Then, the predict_proba() method is called after we fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Setosa</th>\n",
       "      <th>Versicolor</th>\n",
       "      <th>Virginica</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972071</td>\n",
       "      <td>0.014004</td>\n",
       "      <td>0.013925</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.967368</td>\n",
       "      <td>0.017631</td>\n",
       "      <td>0.015001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.957512</td>\n",
       "      <td>0.026308</td>\n",
       "      <td>0.016180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.963583</td>\n",
       "      <td>0.020316</td>\n",
       "      <td>0.016101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.972647</td>\n",
       "      <td>0.013227</td>\n",
       "      <td>0.014126</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.016034</td>\n",
       "      <td>0.956922</td>\n",
       "      <td>0.027044</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.015580</td>\n",
       "      <td>0.947631</td>\n",
       "      <td>0.036789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.012426</td>\n",
       "      <td>0.495200</td>\n",
       "      <td>0.492374</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.986938</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.007293</td>\n",
       "      <td>0.962295</td>\n",
       "      <td>0.030412</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.013001</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.984411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.011166</td>\n",
       "      <td>0.085828</td>\n",
       "      <td>0.903006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.008577</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.987581</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>0.982318</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.988147</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Setosa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Versicolor</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginica</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.969093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Setosa  Versicolor  Virginica      Mean\n",
       "0           0.972071    0.014004   0.013925       NaN\n",
       "10          0.967368    0.017631   0.015001       NaN\n",
       "20          0.957512    0.026308   0.016180       NaN\n",
       "30          0.963583    0.020316   0.016101       NaN\n",
       "40          0.972647    0.013227   0.014126       NaN\n",
       "50          0.016034    0.956922   0.027044       NaN\n",
       "60          0.015580    0.947631   0.036789       NaN\n",
       "70          0.012426    0.495200   0.492374       NaN\n",
       "80          0.006787    0.986938   0.006275       NaN\n",
       "90          0.007293    0.962295   0.030412       NaN\n",
       "100         0.013001    0.002588   0.984411       NaN\n",
       "110         0.011166    0.085828   0.903006       NaN\n",
       "120         0.008577    0.003842   0.987581       NaN\n",
       "130         0.009140    0.008541   0.982318       NaN\n",
       "140         0.009092    0.002761   0.988147       NaN\n",
       "Setosa           NaN         NaN        NaN  0.968917\n",
       "Versicolor       NaN         NaN        NaN  0.963446\n",
       "Virginica        NaN         NaN        NaN  0.969093"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(probability=True)\n",
    "model = classifier.fit(X,y)\n",
    "#model.predict_proba(X)...don't run\n",
    "confidence = pd.DataFrame(model.predict_proba(X)).iloc[::10,:]\n",
    "confidence.columns = ['Setosa', 'Versicolor', 'Virginica']\n",
    "Set = confidence.Setosa[(confidence.Setosa > 0.959666)].mean()\n",
    "Ver = confidence.Versicolor[(confidence.Versicolor > 0.497529)].mean()\n",
    "Vir = confidence.Virginica[(confidence.Virginica > 0.898209)].mean()\n",
    "quickrows = pd.DataFrame([Set, Ver, Vir], index= ['Setosa', 'Versicolor', 'Virginica']\n",
    "                        , columns = ['Mean'])\n",
    "confidence.append(quickrows, sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above chart is a rough sketch of the how confident the classifier is in its predictions. It is important to note that these values are not actually probabilites, and while they may be provide a useful indication about the model, the mathematical soundness of these scores is debatable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. If you train an SVM classifier with an RBF Kernel and you find out that it underfits the training set. Should you increase/ decrease the gamma? What about C? write a code to prove your statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can correct underfitting by increasing c and gamma. Increasing c will make the margins of the decision boundary narrower, which reduces margin violations and makes the decision boundary more responsive to the variance of the training data. To explain the  effect of gamma on fit, it is necessary to discuss 'feature similarity' transformations.\n",
    "\n",
    "We can generate a new feature by selecting a landmark instance and evaluating the relative similarity (distance) of all other instances. If gamma is small, the 'influence' of the landmark instance will be large, and the new feature will represent all other instances as similar to the landmark (even if they are not). If gamma is large, the influence of the landmark instance will be small, and the new feature may underrepresent the similarity of nearby instances. An appropriate gamma will increase the separability of the target class. The process can be repeated m times.\n",
    "\n",
    "We can evaluate whether a classifier is underfitting a model by plotting a learning curve. If the train and test data have a similar error when the set size is sufficiently large, the model is likely underfitting. In this case, it is more appropriate to compare the cross validated accuracy for ranges of c and gamma (selected arbitrarily)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.2,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.1, 1, 5, 10, 100], 'C': [0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_range = [0.1, 1, 5, 10, 100]\n",
    "C_range = [0.001, 0.01, 0.1, 1, 10]\n",
    "classifiers = []\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the docs\n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = grid.cv_results_['mean_test_score'].reshape(len(C_range),\n",
    "                                                     len(gamma_range))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot,\n",
    "           norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "plt.yticks(np.arange(len(C_range)), C_range)\n",
    "plt.title('Validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris data is quite simple, so similarity based transformations have limited use, but margin adjustments appear fairly important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. How can you train a SVM regressor on a sample data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question is slightly ambiguous, but I will get clarification and update the submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
